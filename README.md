# HIV-IMT 条带图像识别与智能分析系统（2025.01 - 2025.04）

本项目聚焦 HIV-IMT 免疫印迹条带图像识别与智能诊断，围绕图像检测、多模态推理与结构化问答，构建从图像识别到自动化诊断的一体化 AI 分析系统。系统结合 YOLOv11s 条带检测模型与 Qwen2.5-vl-32B 大语言模型，通过规则引擎与多模态推理机制，实现条带识别、分类与智能问答自动化，整体准确率达 95% 以上。

---

## 🔍 项目背景

- HIV-IMT 是一种用于 HIV 抗体检测的标准免疫印迹技术，图像识别存在条带偏移、姿态变化与光照干扰等问题，人工判读效率与一致性较低。源数据样例图如下：
![15_18_vaEw_3](https://github.com/user-attachments/assets/7e8b866a-d840-43eb-9da3-96adbe88f424)
![8_10_xuzC_1](https://github.com/user-attachments/assets/759e0c64-4d08-4024-acb8-7be1723b0ed8)
- 项目目标为构建条带图像识别 + 问答式诊断系统，提升结果准确性、自动化程度与用户交互体验。

---

### 📁 核心文件说明

| 文件 / 文件夹路径                           | 内容说明 |
|--------------------------------------------|----------|
| `code/band_process/rag_api_utils.py`        |  实现与FastGPT知识库系统的交互 |
| `code/band_process/utils.py`                |  图像预处理脚本，完成灰度转换、尺寸归一化、旋转矫正等操作 |
| `code/data_train/`                          | YOLOv11s 训练脚本，含 X-AnyLabeling 数据导入与 ONNX 模型导出功能 |
| `code/ultralytics/`                         | ultralytics库文件 |
| `dataset-big/`                              | 自动标注后的数据集（由于数据源归属等问题，此处只展示一部分） |
| `dataset-small/`                            | 人工标注后的数据集（由于数据源归属等问题，此处只展示一部分） |
| `docs/判读IMT膜条流程图.pdf`                 | HIV-IMT条带检测原理+RAG思路梳理文档 |
| `docs/更新说明.docx`                         | 由于FastGPT版本的更新，针对原配置方法的说明 |
| `box_best.pt`                              | 训练后的模型文件 |

---

## 👨‍💻 我的职责

- **独立负责项目设计与实现**，涵盖数据处理、目标检测模型训练、规则文档设计、推理系统部署等关键环节。
- 负责医学规则文档撰写与结构化表达，构建可扩展的 RAG 推理框架。
- 负责本地部署大模型推理系统，完成图像识别结果的语义化输出。

---

## ⚙️ 核心技术方案

| 模块 | 技术 / 工具 | 描述 |
|------|--------------|------|
| 图像预处理 | OpenCV | 灰度化 + 尺寸标准化 + 旋转矫正（crop & rotate） |
| 标注与识别 | YOLOv11s + ONNX | 使用 X-AnyLabeling 工具手工标注 200 张图像，训练轻量模型后进行 1000 张图像自动标注 |
| 模型部署 | FastGPT + Qwen2.5-vl-32B (8bit) | 本地通过Docker部署 FastGPT 前端，远程调用 Qwen 多模态大模型（基于消费级算力租赁平台AutoDL），结合 8-bit 量化加速  |
| 推理机制 | RAG + 医学规则文档 | 构建规则文档与提示词模板，支持自动生成诊断结论并进行语义问答解释 |
| 性能优化 | ONNX、量化推理 | 利用 ONNX 加速推理速度，减少显存占用，单图平均推理时间控制在 3.2 秒 |

---

## 📈 项目成果

- 🔬 条带识别模型 mAP@0.5 达 **91.3%**，点位识别精度 > **93.5%**
- ✅ 条带类型分类准确率达 **95.7%**，包括强阳性、弱阳性、阴性等
- 🧠 模型问答结果可根据图像点位、规则逻辑进行“检测结果解释 + 后续建议”自然语言生成
- ⏱️ 推理延迟压缩至 **3.2 秒 / 图像**，支持远程 GPU 推理与本地低延迟响应

---

## 📌 技术亮点总结

- 独立完成从图像识别到推理诊断的端到端系统搭建，深度结合大模型与医学规则；
- 成功集成轻量模型（YOLOv11s + ONNX）与大模型（Qwen2.5-vl-32B）协同推理；
- 构建可扩展的医学图像规则判断文档体系，支持跨图像类型扩展；
- 综合提升诊断准确性与智能化程度，适用于医学影像领域多种垂类任务。

---

### 🔧 不足与优化策略

本项目虽已完成主要功能目标，但在工程健壮性与交互体验方面仍有优化空间：

#### 1. 规则匹配机制灵活度不足
- **当前问题：** 条带分类依赖预定义 JSON 规则，规则变动需手动修改文档，缺乏动态适配能力。
- **优化方向：** 引入 YAML 或数据库存储 + 可视化规则编辑界面，支持医学专家无代码修改。

#### 2. 多图样本融合与批处理能力缺失
- **当前问题：** 系统每次处理单张图像，缺乏对同一批检测样本的汇总逻辑。
- **优化方向：** 设计图像批处理与诊断聚合模块，提升临床使用效率与报告输出能力。

#### 3. 推理链条尚未完全异步化
- **当前问题：** FastGPT 与 AutoDL 推理调用为同步阻塞式接口，影响整体响应速度。
- **优化方向：** 引入任务队列（如 Celery）和异步 FastAPI 接口，提高吞吐量与稳定性。

#### 4. 模型部署存在资源依赖
- **当前问题：** Qwen2.5 模型依赖远程 8 卡 RTX 3090 GPU 资源，无法本地化部署。
- **优化方向：** 尝试模型裁剪（如 LoRA/Distil）后本地部署 7B 或 13B 量化模型，兼顾性能与成本。

#### 5. 可视化交互尚未构建
- **当前问题：** 当前以 CLI 为主，缺乏用户操作界面。
- **优化方向：** 使用 Streamlit 或 Gradio 构建 Demo 页面，提升展示效果和用户体验。

---

📧 Email: yangjunyuhill@163.com  

